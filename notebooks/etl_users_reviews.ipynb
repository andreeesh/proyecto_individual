{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL australian_user_reviews.csv\n",
    "import json\n",
    "import ast\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import math\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Define la función para realizar el análisis de sentimiento\n",
    "def analyze_sentiment(text):\n",
    "\tanalyzer = SentimentIntensityAnalyzer()\n",
    "\tsentiment = analyzer.polarity_scores(text)\n",
    "\tif sentiment['compound'] >= 0.05:\n",
    "\t\treturn 2\n",
    "\telif sentiment['compound'] <= -0.05:\n",
    "\t\treturn 0\n",
    "\telse:\n",
    "\t\treturn 1\n",
    "\n",
    "user_reviews = []\n",
    "\n",
    "# Abre el archivo y recorrerlo para agregar las reseñas a la lista\n",
    "with open('../data_sources/json/australian_user_reviews.json', encoding='utf-8') as f:\n",
    "\tfor line in f:\n",
    "\t\tobject = json.loads(json.dumps(ast.literal_eval(line)))\n",
    "\t\tuser_reviews.append(object)\n",
    "\n",
    "# Crea el dataframe a partir de la lista\n",
    "df_user_reviews = pd.DataFrame(user_reviews)\n",
    "\n",
    "# Normaliza la columna reviews\n",
    "normalized = pd.json_normalize(user_reviews, record_path=['reviews'], meta=['user_id'] )\n",
    "\n",
    "# Elimina las filas vacias\n",
    "normalized = normalized.dropna()\n",
    "\n",
    "# Eliminar duplicados\n",
    "clean_items = normalized.drop_duplicates(keep='first')\n",
    "\n",
    "clean_items['review'] = clean_items['review'].apply(analyze_sentiment)\n",
    "clean_items['review'].fillna(1, inplace=True)\n",
    "\n",
    "# Dividir el DataFrame en bloques de 1000 filas\n",
    "rows_per_file = 10000\n",
    "total_rows = len(clean_items)\n",
    "total_files = math.ceil(total_rows / rows_per_file)\n",
    "\n",
    "# Recorrer y crear archivos Parquet\n",
    "for i in range(total_files):\n",
    "    s = i * rows_per_file\n",
    "    e = min((i + 1) * rows_per_file, total_rows)\n",
    "    block = clean_items.iloc[s:e]\n",
    "\n",
    "    # Crear el nombre del archivo Parquet (puedes modificar el nombre como desees)\n",
    "    file_name = f\"../data_sources/parquet/user_reviews/dataset_{i + 1}.parquet\"\n",
    "\n",
    "    # Guardar el bloque actual en un archivo Parquet\n",
    "    block.to_parquet(file_name)\n",
    "\n",
    "    print(f\"Archivo {file_name} guardado con éxito. Filas {s + 1} a {e} del DataFrame.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
